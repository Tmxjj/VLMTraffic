import streamlit as st
import pandas as pd
import json
import os
import argparse
from PIL import Image

# å¼•å…¥ç¿»è¯‘åº“
try:
    from deep_translator import GoogleTranslator
except ImportError:
    st.error("è¯·å…ˆå®‰è£…ç¿»è¯‘åº“: pip install deep-translator")
    st.stop()

# --- å‘½ä»¤è¡Œå‚æ•°è§£æ ---
def get_args():
    parser = argparse.ArgumentParser(description="TrafficVLM Case Viewer")
    parser.add_argument("--path", type=str, default="dataset.jsonl", help="æ•°æ®æ–‡ä»¶çš„è·¯å¾„")
    args, _ = parser.parse_known_args()
    return args

args = get_args()
default_data_path = args.path

st.set_page_config(layout="wide", page_title="TrafficVLM Case Viewer")

# --- ç¿»è¯‘è¾…åŠ©å‡½æ•° (å¸¦ç¼“å­˜) ---
@st.cache_data(show_spinner=False)
def translate_text(text):
    if not text:
        return ""
    try:
        # ä½¿ç”¨ Google ç¿»è¯‘æºï¼Œç›®æ ‡è¯­è¨€ä¸ºç®€ä½“ä¸­æ–‡
        translator = GoogleTranslator(source='auto', target='zh-CN')
        # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼ˆè¶…è¿‡5000å­—ç¬¦ï¼‰ï¼ŒGoogleæ¥å£å¯èƒ½ä¼šæŠ¥é”™ï¼Œè¿™é‡Œåšä¸ªç®€å•çš„æˆªæ–­æˆ–åˆ†æ®µå¤„ç†å»ºè®®
        # è¿™é‡Œç›´æ¥ç¿»è¯‘ï¼Œé€šå¸¸ response ä¸ä¼šå¤ªé•¿
        return translator.translate(text)
    except Exception as e:
        return f"ç¿»è¯‘å¤±è´¥: {e} (è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥)"

# --- æ•°æ®åŠ è½½å‡½æ•° ---
@st.cache_data
def load_data(file_path):
    data = []
    content = ""
    try:
        if hasattr(file_path, 'read'):
            content = file_path.read().decode('utf-8')
        else:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
    except FileNotFoundError:
        return pd.DataFrame()

    raw_samples = content.split('-----')

    for sample_str in raw_samples:
        clean_str = sample_str.strip()
        if not clean_str:
            continue
        try:
            obj = json.loads(clean_str)
            data.append(obj)
        except json.JSONDecodeError:
            continue

    return pd.DataFrame(data)

# --- ä¾§è¾¹æ  ---
st.sidebar.title("ğŸ› ï¸ è®¾ç½®ä¸ç­›é€‰")
st.sidebar.subheader("ğŸ“‚ æ•°æ®æ¥æº")
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=["jsonl", "txt"])
df = None

if uploaded_file is not None:
    df = load_data(uploaded_file)
elif default_data_path and os.path.exists(default_data_path):
    st.sidebar.info(f"è¯»å–: `{os.path.basename(default_data_path)}`")
    df = load_data(default_data_path)
else:
    st.error(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: `{default_data_path}`")
    st.stop()

# è·¯å¾„æ˜ å°„
st.sidebar.markdown("---")
path_prefix_to_replace = st.sidebar.text_input("æ•°æ®è·¯å¾„å‰ç¼€ (Old)", "/home/jyf/code/trafficVLM/code/VLMTraffic/")
local_path_prefix = st.sidebar.text_input("æœ¬åœ°è·¯å¾„å‰ç¼€ (New)", "./")

# ç­›é€‰é€»è¾‘
if df is not None and not df.empty:
    st.sidebar.markdown("---")
    
    # è·å–ç­›é€‰é€‰é¡¹
    j_ids = ["All"] + sorted(df['junction_id'].astype(str).unique().tolist()) if 'junction_id' in df else []
    labels = ["All"] + sorted(df['label'].astype(str).unique().tolist()) if 'label' in df else []
    
    sel_jid = st.sidebar.selectbox("Junction ID", j_ids)
    sel_label = st.sidebar.selectbox("Label", labels)
    
    if 'step' in df:
        min_s, max_s = int(df['step'].min()), int(df['step'].max())
        sel_step = st.sidebar.slider("Step Range", min_s, max_s, (min_s, max_s))
    
    # åº”ç”¨ç­›é€‰
    filtered_df = df.copy()
    if sel_jid != "All": filtered_df = filtered_df[filtered_df['junction_id'].astype(str) == sel_jid]
    if sel_label != "All": filtered_df = filtered_df[filtered_df['label'] == sel_label]
    if 'step' in df: filtered_df = filtered_df[(filtered_df['step'] >= sel_step[0]) & (filtered_df['step'] <= sel_step[1])]

    if len(filtered_df) == 0:
        st.warning("æ— åŒ¹é…æ•°æ®")
        st.stop()

    st.sidebar.markdown(f"**æ‰¾åˆ° {len(filtered_df)} æ¡æ•°æ®**")
    
    if 'current_index' not in st.session_state: st.session_state.current_index = 0
    if st.session_state.current_index >= len(filtered_df): st.session_state.current_index = 0

    c1, c2, c3 = st.sidebar.columns([1, 2, 1])
    if c1.button("â¬…ï¸"): st.session_state.current_index = max(0, st.session_state.current_index - 1)
    if c3.button("â¡ï¸"): st.session_state.current_index = min(len(filtered_df) - 1, st.session_state.current_index + 1)
    c2.markdown(f"<center>{st.session_state.current_index + 1} / {len(filtered_df)}</center>", unsafe_allow_html=True)

    row = filtered_df.iloc[st.session_state.current_index]

    # --- ä¸»ç•Œé¢å¸ƒå±€ä¼˜åŒ– ---
    
    # 1. æ ‡é¢˜è¡Œ
    lbl = row.get('label', 'N/A')
    lbl_color = ":green" if lbl == 'accepted' else ":red"
    st.markdown(f"### ğŸš¦ JID: `{row.get('junction_id')}` | Step: `{row.get('step')}` | Label: {lbl_color}[**{lbl}**]")

    # 2. å…³é”®æŒ‡æ ‡è¡Œ (æ”¾åœ¨é¡¶éƒ¨ï¼Œä¸æŒ¤å ä¸‹æ–¹ç©ºé—´)
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Current Phase", row.get('current_phase', 'N/A'))
    m2.metric("VLM Action", row.get('vlm_action', 'N/A'))
    
    opt_act = row.get('optimal_action', 'N/A')
    vlm_act = row.get('vlm_action', 'N/A')
    is_correct = (str(opt_act) == str(vlm_act))
    m3.metric("Optimal Action", opt_act, delta="Correct" if is_correct else "Incorrect", delta_color="normal" if is_correct else "inverse")
    m4.metric("Best Metric Val", round(float(row.get('metric_val', 0)), 2))

    st.divider()

    # 3. å·¦å³åˆ†æ ï¼šå·¦å›¾ï¼Œå³æ–‡
    col_img, col_text = st.columns([1, 1]) # 1:1 æ¯”ä¾‹ï¼Œæˆ–è€… [5,4]

    # --- å·¦ä¾§ï¼šå›¾ç‰‡ ---
    with col_img:
        st.subheader("ğŸ–¼ï¸ Visual Input")
        raw_path = row.get('image_path', '')
        if path_prefix_to_replace and local_path_prefix and raw_path:
            image_path = raw_path.replace(path_prefix_to_replace, local_path_prefix)
        else:
            image_path = raw_path
            
        if image_path and os.path.exists(image_path):
            st.image(image_path, use_column_width=True)
            st.caption(f"Path: {image_path}")
        else:
            st.warning(f"Image not found: {image_path}")

        # å°† Prompt å’Œ Think Process æ”¾åœ¨å›¾ç‰‡ä¸‹æ–¹
        with st.expander("System Prompt"):
            st.text(row.get('prompt', ''))
        with st.expander("Think Process (Chain of Thought)"):
            st.write(row.get('vlm_think_process', ''))

    # --- å³ä¾§ï¼šç¿»è¯‘åçš„å›å¤ & å›¾è¡¨ ---
    with col_text:
        st.subheader("ğŸ¤– VLM Analysis (CN/EN)")
        
        raw_response = row.get('vlm_response_raw', '')
        
        # ç¿»è¯‘å¼€å…³
        show_trans = st.toggle("å¯ç”¨ä¸­æ–‡ç¿»è¯‘ (Translate to Chinese)", value=True)
        
        if show_trans and raw_response:
            with st.spinner("æ­£åœ¨ç¿»è¯‘..."):
                translated_text = translate_text(raw_response)
            
            # ä½¿ç”¨ info æ¡†é«˜äº®æ˜¾ç¤ºç¿»è¯‘å†…å®¹
            st.success(f"**ä¸­æ–‡å›å¤:**\n\n{translated_text}")
            
            # åœ¨æŠ˜å æ¡†ä¸­ä¿ç•™åŸæ–‡ï¼Œæ–¹ä¾¿å¯¹ç…§
            with st.expander("æŸ¥çœ‹è‹±æ–‡åŸæ–‡ (Original English)"):
                st.code(raw_response, language="text")
        else:
            # ä¸ç¿»è¯‘æ—¶ç›´æ¥æ˜¾ç¤º
            st.info(f"**Raw Response:**\n\n{raw_response}")

        st.divider()

        # å›¾è¡¨æ”¾åœ¨æ–‡å­—ä¸‹æ–¹
        st.subheader("ğŸ“Š Reward Metrics")
        metrics_dict = row.get('all_metrics', {})
        if metrics_dict:
            try:
                metrics_df = pd.DataFrame(list(metrics_dict.items()), columns=['Phase', 'Reward'])
                metrics_df['Phase'] = metrics_df['Phase'].astype(str)
                # ç®€å•é«˜äº® VLM é€‰æ‹©çš„ Phase
                colors = []
                for p in metrics_df['Phase']:
                    if str(p) == str(vlm_act):
                        colors.append("#ff4b4b") # çº¢è‰²é«˜äº®é€‰ä¸­çš„
                    elif str(p) == str(opt_act):
                         colors.append("#09ab3b") # ç»¿è‰²é«˜äº®æœ€ä¼˜çš„(å¦‚æœä¸é‡åˆ)
                    else:
                        colors.append("#e6e9ef") # ç°è‰²
                
                st.bar_chart(metrics_df.set_index('Phase')['Reward'], color=colors if len(colors)==len(metrics_df) else None)
                
                # åŒæ—¶ä¹Ÿæ˜¾ç¤ºè¡¨æ ¼ï¼Œæ–¹ä¾¿çœ‹å…·ä½“æ•°å€¼
                st.dataframe(metrics_df.set_index('Phase').T)
            except Exception as e:
                st.write(metrics_dict)
else:
    st.info("è¯·åŠ è½½æ•°æ®ã€‚")

    # è¿è¡Œè„šæœ¬ï¼šstreamlit run scripts/viewer.py -- --path data/sft_dataset/JiNan_test/dataset.jsonl