import streamlit as st
import pandas as pd
import json
import os
import argparse
import re
import time
# å¼•å…¥ç¿»è¯‘åº“
try:
    from deep_translator import GoogleTranslator
except ImportError:
    pass # ä¸‹é¢æœ‰æ£€æŸ¥é€»è¾‘

# --- 1. æ ¸å¿ƒå·¥å…·å‡½æ•° ---

def format_vlm_response(text):
    if not text: return ""
    # --- æ·±åº¦æ¸…æ´— ---
    text = text.replace('\xa0', ' ')
    text = text.replace("Thought: [", "").strip()
    if text.endswith("]"):
        text = text[:-1]
    # --- å¼ºåˆ¶æ‹å¹³æ–‡æœ¬ ---
    clean_text = " ".join([line.strip() for line in text.split('\n') if line.strip()])
    # --- ä¸€çº§æ ‡é¢˜ ---
    primary_keywords = ["1. Scene Understanding", "2. Scene Analysis", "3. Selection Logic"]
    for key in primary_keywords:
        if key in clean_text:
            clean_text = clean_text.replace(key, f"\n\n**{key}**")
    # --- äºŒçº§æ ‡é¢˜ ---
    secondary_keywords = [
        "- [Phase 0]", "- [Phase 1]", "- [Phase 2]", "- [Phase 3]", "- [Phase 4]",
        "- Emergency Check", "- Final Condition", 
        "- Rule Identification", "- Conclusion", "- Reasoning"
    ]
    for tag in secondary_keywords:
        if tag in clean_text:
            label = tag.replace("- ", "").strip()
            clean_text = clean_text.replace(tag, f"\n- **{label}**")
    # --- å¤„ç† Action ---
    if "Action:" in clean_text:
        clean_text = clean_text.replace("Action:", "\n\n---\n### ğŸ Action:")
    return clean_text.strip()

@st.cache_data(show_spinner=False)
def translate_text(text):
    if not text: return ""
    try:
        translator = GoogleTranslator(source='auto', target='zh-CN')
        return translator.translate(text)
    except Exception as e:
        return f"ç¿»è¯‘å¤±è´¥: {e}"

@st.cache_data
def load_data(file_path):
    data = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        return pd.DataFrame()
    raw_samples = content.split('-----')
    for sample_str in raw_samples:
        clean_str = sample_str.strip()
        if not clean_str: continue
        try:
            obj = json.loads(clean_str)
            data.append(obj)
        except json.JSONDecodeError:
            continue
    return pd.DataFrame(data)

def get_annotated_path(input_path):
    base, ext = os.path.splitext(input_path)
    return f"{base}_annotated{ext}"

# --- æ•°æ®åŠ è½½ä¸ä¿å­˜é€»è¾‘å‡çº§ ---
def load_existing_annotations(anno_path):
    """
    è¯»å–æ”¯æŒç¼©è¿›æ ¼å¼ (Pretty-printed) çš„å †å  JSON æ–‡ä»¶
    """
    annotations = {}
    if not os.path.exists(anno_path):
        return annotations
    
    with open(anno_path, 'r', encoding='utf-8') as f:
        content = f.read().strip()
        if not content:
            return annotations
        
        # ä½¿ç”¨ raw_decode å¾ªç¯è§£æå †å çš„ JSON å¯¹è±¡
        decoder = json.JSONDecoder()
        pos = 0
        while pos < len(content):
            # è·³è¿‡ç©ºç™½å­—ç¬¦
            try:
                while pos < len(content) and content[pos].isspace():
                    pos += 1
                if pos >= len(content):
                    break
                
                # è§£æä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡
                obj, idx = decoder.raw_decode(content[pos:])
                pos += idx
                
                # å­˜å…¥å­—å…¸
                if isinstance(obj, dict):
                    uid = f"{obj.get('junction_id')}_{obj.get('step')}"
                    annotations[uid] = obj
            except json.JSONDecodeError:
                # é‡åˆ°è§£æé”™è¯¯è·³è¿‡æˆ–åœæ­¢
                print(f"è§£æè­¦å‘Š: åœ¨ä½ç½® {pos} é™„è¿‘å‘ç°æ— æ³•è§£æçš„å†…å®¹")
                break
                
    return annotations

def save_annotation_line(anno_path, record):
    """
    ä»¥ç¼©è¿›æ ¼å¼ (Indent=4) è¿½åŠ ä¿å­˜ JSON
    """
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(os.path.abspath(anno_path)) or ".", exist_ok=True)
    
    with open(anno_path, 'a', encoding='utf-8') as f:
        # ä½¿ç”¨ ensure_ascii=False ä¿è¯ä¸­æ–‡æ­£å¸¸æ˜¾ç¤º
        # ä½¿ç”¨ indent=4 ä¿è¯å¯è¯»æ€§
        json_str = json.dumps(record, ensure_ascii=False, indent=4)
        f.write(json_str + "\n")

# --- 2. é¡µé¢ä¸ä¾§è¾¹æ é…ç½® ---
def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--path", type=str, default="dataset.jsonl")
    args, _ = parser.parse_known_args()
    return args

args = get_args()
default_data_path = args.path

st.set_page_config(layout="wide", page_title="TrafficVLM Case Viewer")

st.sidebar.title("ğŸ› ï¸ è®¾ç½®ä¸ç­›é€‰")

# åŠ è½½æ•°æ®
df = None
if default_data_path and os.path.exists(default_data_path):
    df = load_data(default_data_path)
else:
    st.error(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: `{default_data_path}`")
    st.stop()

# åŠ è½½æ ‡æ³¨è·¯å¾„
annotated_file_path = get_annotated_path(default_data_path)
existing_annos = load_existing_annotations(annotated_file_path)

st.sidebar.info(f"å·²æ ‡æ³¨: {len(existing_annos)} æ¡ | ä¿å­˜è‡³: {os.path.basename(annotated_file_path)}")
st.sidebar.markdown("---")

# è·¯å¾„å‰ç¼€è®¾ç½®
path_prefix_to_replace = st.sidebar.text_input("æ•°æ®è·¯å¾„å‰ç¼€ (Old)", "/home/jyf/code/trafficVLM/code/VLMTraffic/")
local_path_prefix = st.sidebar.text_input("æœ¬åœ°è·¯å¾„å‰ç¼€ (New)", "./")

# ç­›é€‰é€»è¾‘
if df is not None and not df.empty:
    st.sidebar.markdown("---")
    j_ids = ["All"] + sorted(df['junction_id'].astype(str).unique().tolist()) if 'junction_id' in df else []
    labels = ["All"] + sorted(df['label'].astype(str).unique().tolist()) if 'label' in df else []
    
    sel_jid = st.sidebar.selectbox("Junction ID", j_ids)
    sel_label = st.sidebar.selectbox("Label (Auto)", labels)
    
    if 'step' in df:
        min_s, max_s = int(df['step'].min()), int(df['step'].max())
        sel_step = st.sidebar.slider("Step Range", min_s, max_s, (min_s, max_s))
    
    filtered_df = df.copy()
    if sel_jid != "All": filtered_df = filtered_df[filtered_df['junction_id'].astype(str) == sel_jid]
    if sel_label != "All": filtered_df = filtered_df[filtered_df['label'] == sel_label]
    if 'step' in df: filtered_df = filtered_df[(filtered_df['step'] >= sel_step[0]) & (filtered_df['step'] <= sel_step[1])]

    if len(filtered_df) == 0:
        st.warning("æ— åŒ¹é…æ•°æ®")
        st.stop()
    
    # ç¿»é¡µæ§åˆ¶
    if 'current_index' not in st.session_state: st.session_state.current_index = 0
    if st.session_state.current_index >= len(filtered_df): st.session_state.current_index = 0

    c1, c2, c3 = st.sidebar.columns([1, 2, 1])
    if c1.button("â¬…ï¸"): st.session_state.current_index = max(0, st.session_state.current_index - 1)
    if c3.button("â¡ï¸"): st.session_state.current_index = min(len(filtered_df) - 1, st.session_state.current_index + 1)
    c2.markdown(f"<center>{st.session_state.current_index + 1} / {len(filtered_df)}</center>", unsafe_allow_html=True)

    row = filtered_df.iloc[st.session_state.current_index]
    current_uid = f"{row.get('junction_id')}_{row.get('step')}"
    prev_anno = existing_annos.get(current_uid, None)

    # --- ä¸»ç•Œé¢ ---
    lbl = row.get('label', 'N/A')
    lbl_color = ":green" if lbl == 'accepted' else ":red"
    anno_status = "âœ… å·²äººå·¥æ ‡æ³¨" if prev_anno else "â¬œ æœªæ ‡æ³¨"
    
    st.markdown(f"### ğŸš¦ JID: `{row.get('junction_id')}` | Step: `{row.get('step')}` | {lbl_color}[**{lbl}**] | {anno_status}")

    # æŒ‡æ ‡æ 
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Current Phase", row.get('current_phase', 'N/A'))
    m2.metric("VLM Action", row.get('vlm_action', 'N/A'))
    opt_act = row.get('optimal_action', 'N/A')
    vlm_act = row.get('vlm_action', 'N/A')
    is_correct = (str(opt_act) == str(vlm_act))
    m3.metric("Optimal Action", opt_act, delta="Correct" if is_correct else "Incorrect", delta_color="normal" if is_correct else "inverse")
    m4.metric("Best Metric Val", round(float(row.get('metric_val', 0)), 2))

    st.divider()

    # ==========================================
    # ğŸ“ å¸ƒå±€ä¿®æ”¹ï¼šä¸‰æ å¸ƒå±€
    # [Visuals (40%)]  [VLM Analysis (30%)]  [Annotation (30%)]
    # ==========================================
    col_visual, col_analysis, col_anno = st.columns([4, 3, 3])

    # --- ç¬¬1æ ï¼šVisual Input ---
    with col_visual:
        st.subheader("ğŸ–¼ï¸ Visual Input")
        raw_path = row.get('image_path', '')
        if path_prefix_to_replace and local_path_prefix and raw_path:
            image_path = raw_path.replace(path_prefix_to_replace, local_path_prefix)
        else:
            image_path = raw_path
            
        if image_path and os.path.exists(image_path):
            st.image(image_path, use_column_width=True)
            st.caption(f"Path: {image_path}")
        else:
            st.warning(f"Image not found: {image_path}")

        with st.expander("System Prompt"):
            st.text(row.get('prompt', ''))
        with st.expander("Think Process (Chain of Thought)"):
            st.write(row.get('vlm_think_process', ''))

    # --- ç¬¬2æ ï¼šVLM Analysis & Charts ---
    with col_analysis:
        st.subheader("ğŸ¤– VLM Analysis")
        raw_response = row.get('vlm_response_raw', '')
        display_text = format_vlm_response(raw_response)

        # ç¿»è¯‘
        enable_trans = st.toggle("ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç¿»è¯‘", value=False)
        if enable_trans:
            translated_text = translate_text(display_text)
            st.markdown(translated_text, unsafe_allow_html=True)
            with st.expander("Show Original"):
                st.markdown(display_text, unsafe_allow_html=True)
        else:
            st.markdown(display_text, unsafe_allow_html=True)

        st.markdown("---")
        st.caption("ğŸ“Š Reward Metrics")
        metrics_dict = row.get('all_metrics', {})
        if metrics_dict:
            try:
                metrics_df = pd.DataFrame(list(metrics_dict.items()), columns=['Phase', 'Reward'])
                metrics_df['Phase'] = metrics_df['Phase'].astype(str)
                colors = []
                for p in metrics_df['Phase']:
                    if str(p) == str(vlm_act): colors.append("#ff4b4b")
                    elif str(p) == str(opt_act): colors.append("#09ab3b")
                    else: colors.append("#e6e9ef")
                st.bar_chart(metrics_df.set_index('Phase')['Reward'], color=colors if len(colors)==len(metrics_df) else None)
            except: pass

    # --- ç¬¬3æ ï¼šHuman Annotation (æ”¾åœ¨å³ä¾§) ---
    with col_anno:
        st.subheader("âœï¸ Human Annotation")
        
        # --- 1. å‡†å¤‡é»˜è®¤å€¼ ---
        default_tag = "æ— è¯¯"
        default_text = display_text
        default_remark = "" # æ–°å¢å¤‡æ³¨é»˜è®¤å€¼

        if prev_anno:
            default_tag = prev_anno.get('human_label', 'æ— è¯¯')
            default_remark = prev_anno.get('error_reason', "") # è¯»å–å†å²å¤‡æ³¨
            
            # å¦‚æœæ˜¯"æ— è¯¯"ï¼Œé»˜è®¤æ–‡æœ¬é‡ç½®ä¸ºå½“å‰ç”Ÿæˆçš„ display_text
            if prev_anno.get('human_label') == 'æ— è¯¯':
                 default_text = display_text
            else:
                 default_text = prev_anno.get('corrected_response', display_text)
        
        st.info(f"å½“å‰çŠ¶æ€: **{default_tag}**")

        # --- 2. æ ‡ç­¾é€‰æ‹© (ç§»å‡º Form ä»¥æ”¯æŒäº¤äº’) ---
        tag_options = ["æ— è¯¯", "è§†è§‰ç†è§£æœ‰è¯¯", "å†³ç­–æ¨ç†æœ‰è¯¯"]
        try:
            idx = tag_options.index(default_tag)
        except ValueError:
            idx = 0
        
        selected_tag = st.radio(
            "è¯„ä¼°æ ‡ç­¾ (Select Label):", 
            tag_options, 
            index=idx, 
            horizontal=True,
            key=f"radio_{current_uid}" 
        )

        # é€»è¾‘åˆ¤æ–­
        is_error = (selected_tag != "æ— è¯¯") # æ˜¯å¦ä¸ºé”™è¯¯ç±»å‹
        is_disabled_edit = (not is_error)   # æ˜¯å¦ç¦ç”¨ç¼–è¾‘ (ä»…æ— è¯¯æ—¶ç¦ç”¨)

        # --- 3. é”™è¯¯åŸå› å¤‡æ³¨ (æ–°å¢åŠŸèƒ½) ---
        error_remark = ""
        if is_error:
            st.markdown("---")
            st.caption("ğŸ“ **é”™è¯¯åŸå› è¯´æ˜ (Error Explanation):**")
            error_remark = st.text_input(
                "ç®€è¦è¯´æ˜é”™è¯¯ç‚¹ (ä¾‹å¦‚: æœªè¯†åˆ«å‡ºæ•‘æŠ¤è½¦ / æ‹¥å µåˆ¤æ–­é”™è¯¯)",
                value=default_remark,
                key=f"remark_{current_uid}",
                help="è¯·ç®€è¦æè¿°æ¨¡å‹å…·ä½“å“ªé‡Œé”™äº†"
            )
        
        # --- 4. ä¿®æ­£å›å¤åŒºåŸŸ ---
        st.markdown("---")
        st.caption("ğŸ“ **ä¿®æ­£å›å¤ (Corrected Response):**")
        
        if is_disabled_edit:
            st.warning("ğŸ”’ æ ‡ç­¾ä¸ºâ€œæ— è¯¯â€æ—¶ï¼Œå†…å®¹ä¸å¯ç¼–è¾‘ã€‚")

        # ä½¿ç”¨ Tabs åˆ†ç¦»ç¼–è¾‘å’Œé¢„è§ˆ
        tab_edit, tab_preview = st.tabs(["âœï¸ ç¼–è¾‘ (Edit)", "ğŸ‘ï¸ å®æ—¶é¢„è§ˆ (Preview)"])
        
        with tab_edit:
            corrected_text = st.text_area(
                "Markdown Source", 
                value=default_text, 
                height=500,
                label_visibility="collapsed",
                disabled=is_disabled_edit, 
                key=f"text_{current_uid}"
            )
        
        with tab_preview:
            preview_content = display_text if is_disabled_edit else corrected_text
            if preview_content:
                st.markdown(preview_content, unsafe_allow_html=True)
            else:
                st.caption("æš‚æ— å†…å®¹")

        st.markdown("---")

        # --- 5. ä¿å­˜æäº¤ ---
        with st.form(key=f"save_form_{current_uid}"):
            submitted = st.form_submit_button("ğŸ’¾ ä¿å­˜æ ‡æ³¨ (Save)", use_container_width=True)

            if submitted:
                # æ ¡éªŒé€»è¾‘ï¼šå¦‚æœæ˜¯é”™è¯¯ç±»å‹ï¼Œå»ºè®®å¡«å†™å¤‡æ³¨ï¼ˆå¯é€‰ï¼Œè¿™é‡Œä¸åšå¼ºåˆ¶æ‹¦æˆªï¼Œåªåšæ•°æ®å¤„ç†ï¼‰
                
                final_saved_text = ""
                final_remark = ""

                if selected_tag == "æ— è¯¯":
                    final_saved_text = display_text 
                    final_remark = "" # æ— è¯¯æ—¶æ¸…ç©ºå¤‡æ³¨
                else:
                    final_saved_text = corrected_text.strip()
                    final_remark = error_remark.strip()

                # æ„å»ºä¿å­˜å¯¹è±¡
                save_record = row.to_dict()
                save_record['human_label'] = selected_tag
                save_record['corrected_response'] = final_saved_text
                save_record['error_reason'] = final_remark # [æ–°å¢] ä¿å­˜å¤‡æ³¨å­—æ®µ
                
                if 'index' in save_record: del save_record['index']

                try:
                    save_annotation_line(annotated_file_path, save_record)
                    existing_annos[current_uid] = save_record
                    
                    st.success(f"âœ… å·²ä¿å­˜! ({selected_tag})")
                    time.sleep(0.5)
                    st.rerun()
                except Exception as e:
                    st.error(f"ä¿å­˜å¤±è´¥: {e}")

else:
    st.info("è¯·åŠ è½½æ•°æ®ã€‚")