# Training Configuration (SFT & DPO)

sft:
  output_dir: "models/checkpoints/sft"
  num_train_epochs: 3
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2e-5
  save_steps: 500
  logging_steps: 10
  max_seq_length: 2048

dpo:
  output_dir: "models/checkpoints/dpo"
  beta: 0.1
  num_train_epochs: 1
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  learning_rate: 1e-6
  save_steps: 100
  logging_steps: 5
